{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) UC1: Anomaly Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/benfenati/code/tle-supervised/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Algorithms.models_audio_mae_evaluate import audioMae_vit_base_evaluate\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import *\n",
    "from util.engine_pretrain import evaluate\n",
    "from plot_anomaly import compute_threshold_accuracy\n",
    "\n",
    "import datetime\n",
    "\n",
    "from Datasets.AnomalyDetection_SS335.get_dataset import get_dataset as get_dataset_ss335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "dir = \"/home/benfenati/code/Datasets/SHM/AnomalyDetection_SS335/\"\n",
    "window_size = 1190\n",
    "lr = 0.25e-2\n",
    "total_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device)\n",
    "teacher = audioMae_vit_base_evaluate(norm_pix_loss=False)\n",
    "teacher.to(device)\n",
    "# checkpoint = torch.load(f\"/home/benfenati/code/tle-supervised/checkpoints/checkpoint-pretrain_all-200.pth\", map_location='cpu')\n",
    "checkpoint = torch.load(f\"/home/benfenati/code/tle-supervised/Results/checkpoints/checkpoint--400.pth\", map_location='cpu')\n",
    "checkpoint_model = checkpoint['model']\n",
    "msg = teacher.load_state_dict(checkpoint_model, strict=False)\n",
    "\n",
    "params, size = get_model_info(teacher)\n",
    "print(\"params={} | size={:.3f} MB\".format(millify(params), size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 384 # 96, 192, 384, 768(original)\n",
    "decoder_embed_dim = 256 # 64, 128, 256, 512(original)\n",
    "student = audioMae_vit_base_evaluate(embed_dim=embed_dim, decoder_embed_dim=decoder_embed_dim, norm_pix_loss=False)\n",
    "student.to(device)\n",
    "\n",
    "params, size = get_model_info(student)\n",
    "print(\"params={} | size={:.3f} MB\".format(millify(params), size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_date = datetime.date(2019,5,22) \n",
    "num_days = 7\n",
    "print(\"Creating Training Dataset\")\n",
    "dataset = get_dataset_ss335(dir, starting_date, num_days, sensor = 'S6.1.3', time_frequency = \"frequency\", windowLength = window_size)\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset)\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset, sampler=sampler_train,\n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True,\n",
    ")\n",
    "device = torch.device(device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "loss_fn_1 = nn.L1Loss()\n",
    "loss_fn_2 = nn.L1Loss()\n",
    "loss_fn_3 = nn.MSELoss()\n",
    "\n",
    "teacher.eval()\n",
    "\n",
    "b = 0.5\n",
    "\n",
    "best_loss = 100000000\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    student.train()\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "    for samples, targets in data_loader_train:\n",
    "        samples = samples.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss_student, pred_student, _ = student(samples, mask_ratio=0.8)\n",
    "\n",
    "        with torch.no_grad() and torch.cuda.amp.autocast():\n",
    "            teacher.eval()\n",
    "            loss_teacher, pred_teacher, _ = teacher(samples, mask_ratio=0.8)\n",
    "        \n",
    "        \n",
    "        loss_1 = loss_student\n",
    "        loss_2 = loss_fn_3(pred_student, pred_teacher)\n",
    "        \n",
    "        loss = b*loss_1 + (1-b)*loss_2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss_student.item()\n",
    "        # train_loss += loss.item()\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = student\n",
    "who = \"student\"\n",
    "\n",
    "### Creating Testing Dataset for Normal Data\n",
    "starting_date = datetime.date(2019,5,10)\n",
    "num_days = 4\n",
    "print(\"Creating Testing Dataset -- Normal\")\n",
    "dataset = get_dataset_ss335(dir, starting_date, num_days, sensor = 'S6.1.3', time_frequency = \"frequency\", windowLength = window_size)\n",
    "data_loader_test_normal = torch.utils.data.DataLoader(\n",
    "    dataset, shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True,\n",
    ")\n",
    "losses_normal, _ = evaluate(data_loader_test_normal, model_to_evaluate, device)\n",
    "df = pd.DataFrame.from_dict(losses_normal)\n",
    "df.to_csv(f'Results/masked_{window_size}samples_normal_{who}.csv', index = False, header = True)\n",
    "    \n",
    "### Creating Testing Dataset for Anomaly Data\n",
    "starting_date = datetime.date(2019,4,17) \n",
    "num_days = 4\n",
    "print(\"Creating Testing Dataset -- Anomaly\")\n",
    "dataset = get_dataset_ss335(dir, starting_date, num_days, sensor = 'S6.1.3', time_frequency = \"frequency\", windowLength = window_size)\n",
    "data_loader_test_anomaly = torch.utils.data.DataLoader(\n",
    "    dataset, shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True,\n",
    ")\n",
    "losses_anomaly, _ = evaluate(data_loader_test_anomaly, model_to_evaluate, device)\n",
    "df = pd.DataFrame.from_dict(losses_anomaly)\n",
    "df.to_csv(f'Results/masked_{window_size}samples_anomaly_{who}.csv', index = False, header = True)\n",
    "\n",
    "directory = \"/home/benfenati/code/tle-supervised/Results/\"\n",
    "acc_enc = []\n",
    "sens_enc = []\n",
    "spec_enc = []\n",
    "\n",
    "for dim_filtering in [15,30,60,120, 240]:\n",
    "    print(f\"Dim {dim_filtering}\")\n",
    "    print(f\"Autoencoder\")\n",
    "    data_normal = pd.read_csv(directory + f\"masked_{window_size}samples_normal_{who}.csv\")\n",
    "    data_anomaly = pd.read_csv(directory + f\"masked_{window_size}samples_anomaly_{who}.csv\")\n",
    "    spec, sens, acc = compute_threshold_accuracy(data_anomaly.values, data_normal.values, None, min, max, only_acc = 1, dim_filtering = dim_filtering)\n",
    "    acc_enc.append(acc*100)\n",
    "    sens_enc.append(sens*100)\n",
    "    spec_enc.append(spec*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) UC2: TLE on Roccaprebalza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from Algorithms.models_audio_mae_regression import audioMae_vit_base_R\n",
    "from Algorithms.models_audio_mae_regression_modified import audioMae_vit_base_R\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from time import time\n",
    "from utils import *\n",
    "import util.misc as misc\n",
    "from util.misc import interpolate_pos_embed\n",
    "\n",
    "import datetime\n",
    "from Datasets.Vehicles_Roccaprebalza.get_dataset import get_dataset as get_dataset_roccaprebalza\n",
    "\n",
    "from util.engine_pretrain import evaluate_finetune\n",
    "from vehicles_roccaprebalza_example import compute_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "car = \"y_camion\" # y_car, y_camion\n",
    "dir = \"/home/benfenati/code/Datasets/SHM/Vehicles_Roccaprebalza/\"\n",
    "\n",
    "lr = 0.25e-5\n",
    "total_epochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = audioMae_vit_base_R(norm_pix_loss=True, mask_ratio = 0.2)\n",
    "teacher.to(device)\n",
    "checkpoint = torch.load(f\"/home/benfenati/code/tle-supervised/Results/checkpoints/checkpoint-pretrainig_all_{car}_roccaprebalza_finetune-500.pth\", map_location='cpu')\n",
    "checkpoint_model = checkpoint['model']\n",
    "state_dict = teacher.state_dict()\n",
    "msg = teacher.load_state_dict(checkpoint_model, strict=True)\n",
    "\n",
    "params, size = get_model_info(teacher)\n",
    "print(\"params={} | size={:.3f} MB\".format(millify(params), size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 96 # 96, 192, 384, 768 (original)\n",
    "decoder_embed_dim = 512 # 256, 512 (original)\n",
    "student = audioMae_vit_base_R(embed_dim=embed_dim, decoder_embed_dim=decoder_embed_dim, \n",
    "                              norm_pix_loss=True, mask_ratio = 0.2)\n",
    "student.to(device)\n",
    "checkpoint = torch.load(f\"/home/benfenati/code/tle-supervised/Results/checkpoints/checkpoint-student372-pretrain_all-200.pth\", map_location='cpu')\n",
    "checkpoint_model = checkpoint['model']\n",
    "state_dict = student.state_dict()\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "msg = student.load_state_dict(checkpoint_model, strict=False)\n",
    "interpolate_pos_embed(student, checkpoint_model)\n",
    "\n",
    "params, size = get_model_info(student)\n",
    "print(\"params={} | size={:.3f} MB\".format(millify(params), size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "dataset_train, dataset_test = get_dataset_roccaprebalza(dir, window_sec_size = 60, shift_sec_size = 2, time_frequency = \"frequency\", car = car)\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, sampler=sampler_train,\n",
    "    batch_size=8,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True,\n",
    "    )\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device(device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "optimizer = optim.Adam(student.parameters(), lr=lr, weight_decay=1e-6)\n",
    "loss_fn_1 = nn.L1Loss()\n",
    "loss_fn_2 = nn.L1Loss()\n",
    "loss_fn_3 = nn.MSELoss()\n",
    "\n",
    "teacher.eval()\n",
    "\n",
    "b = 0.5\n",
    "g = 0.6667\n",
    "\n",
    "best_loss = 100000000\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    student.train()\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "    for samples, targets in data_loader_train:\n",
    "        samples = samples.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            middle_student, final_student = student(samples)\n",
    "\n",
    "        with torch.no_grad() and torch.cuda.amp.autocast():\n",
    "            teacher.eval()\n",
    "            middle_teacher, final_teacher = teacher(samples)\n",
    "        \n",
    "        final_student = final_student.squeeze()\n",
    "        final_teacher = final_teacher.squeeze()\n",
    "        # print(\"student\", middle_student.shape, final_student.shape)\n",
    "        # print(\"teacher\", middle_teacher.shape, final_teacher.shape)\n",
    "        loss_1 = loss_fn_1(final_student, targets.float())\n",
    "        loss_2 = loss_fn_2(final_student, final_teacher)\n",
    "\n",
    "\n",
    "        loss_3 = loss_fn_3(middle_student, middle_teacher)\n",
    "        \n",
    "        loss = g*(b*loss_1 + (1-b)*loss_2) + (1-g)*loss_3\n",
    "        # loss = b*loss_1 + (1-b)*loss_2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss_fn_1(final_student, targets).item()\n",
    "        # train_loss += loss_1.item()\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = student\n",
    "\n",
    "dataset_train, dataset_test = get_dataset_roccaprebalza(dir, window_sec_size = 60, shift_sec_size = 2, time_frequency = \"frequency\", car = car)\n",
    "sampler_test = torch.utils.data.RandomSampler(dataset_test)\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "y_predicted, y_test = evaluate_finetune(data_loader_test, model_to_evaluate, device)\n",
    "compute_accuracy(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UC3: TLE on Sacertis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from Algorithms.models_audio_mae_regression import audioMae_vit_base_R\n",
    "from Algorithms.models_audio_mae_regression_modified import audioMae_vit_base_R\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from time import time\n",
    "from utils import *\n",
    "import util.misc as misc\n",
    "from util.misc import interpolate_pos_embed\n",
    "\n",
    "import datetime\n",
    "from Datasets.Vehicles_Sacertis.get_dataset import get_dataset as get_dataset_sacertis\n",
    "\n",
    "from util.engine_pretrain import evaluate_finetune\n",
    "from vehicles_roccaprebalza_example import compute_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "dir = \"/home/benfenati/code/Datasets/SHM/Vehicles_Sacertis/\"\n",
    "\n",
    "lr = 0.25e-3\n",
    "total_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = audioMae_vit_base_R(norm_pix_loss=True, mask_ratio = 0.2)\n",
    "teacher.to(device)\n",
    "checkpoint = torch.load(f\"/home/benfenati/code/tle-supervised/Results/checkpoints/checkpoint-pretrainig_all_vehicles_sacertis_finetune-200.pth\", map_location='cpu')\n",
    "checkpoint_model = checkpoint['model']\n",
    "state_dict = teacher.state_dict()\n",
    "msg = teacher.load_state_dict(checkpoint_model, strict=True)\n",
    "\n",
    "params, size = get_model_info(teacher)\n",
    "print(\"N. params = {}; Size = {:.3f}\".format(params, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 384 # 768 (original)\n",
    "decoder_embed_dim = 512 # 256, 512 (original)\n",
    "student = audioMae_vit_base_R(embed_dim=embed_dim, decoder_embed_dim=decoder_embed_dim, \n",
    "                              norm_pix_loss=True, mask_ratio = 0.2)\n",
    "student.to(device)\n",
    "checkpoint = torch.load(f\"/home/benfenati/code/tle-supervised/Results/checkpoints/checkpoint-student-pretrain_all-200.pth\", map_location='cpu')\n",
    "checkpoint_model = checkpoint['model']\n",
    "state_dict = student.state_dict()\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "msg = student.load_state_dict(checkpoint_model, strict=False)\n",
    "interpolate_pos_embed(student, checkpoint_model)\n",
    "\n",
    "params, size = get_model_info(student)\n",
    "print(\"N. params = {}; Size = {:.3f}\".format(params, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "dataset_train = get_dataset_sacertis(dir, False, True, False,  sensor = \"None\", time_frequency = \"frequency\")\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, sampler=sampler_train,\n",
    "    batch_size=128,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True)\n",
    "\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "device = torch.device(device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "optimizer = optim.Adam(student.parameters(), lr=lr, weight_decay=1e-6)\n",
    "loss_fn_1 = nn.L1Loss()\n",
    "loss_fn_2 = nn.L1Loss()\n",
    "loss_fn_3 = nn.MSELoss()\n",
    "\n",
    "teacher.eval()\n",
    "\n",
    "b = 0.5\n",
    "g = 0.6667\n",
    "\n",
    "best_loss = 100000000\n",
    "best_epoch = 0\n",
    "\n",
    "print(f\"Number of samples in the dataset: {len(data_loader_train)}\")\n",
    "print(f\"Size of the first sample in the dataset: {dataset_train[0][0].size()}\")\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    student.train()\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "    if counter != 0:\n",
    "        print(f\"Epoch {epoch} - Loss {train_loss/counter}\")\n",
    "\n",
    "    for samples, targets in data_loader_train:\n",
    "        if counter % 10 == 0 and counter != 0: \n",
    "            print(f\"Epoch {epoch} - Loss {train_loss/counter}\")\n",
    "        samples = samples.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            middle_student, final_student = student(samples)\n",
    "\n",
    "        with torch.no_grad() and torch.cuda.amp.autocast():\n",
    "            teacher.eval()\n",
    "            middle_teacher, final_teacher = teacher(samples)\n",
    "        \n",
    "        final_student = final_student.squeeze()\n",
    "        final_teacher = final_teacher.squeeze()\n",
    "        loss_1 = loss_fn_1(final_student, targets.float())\n",
    "        loss_2 = loss_fn_2(final_student, final_teacher)\n",
    "\n",
    "\n",
    "        loss_3 = loss_fn_3(middle_student, middle_teacher)\n",
    "        \n",
    "        loss = g*(b*loss_1 + (1-b)*loss_2) + (1-g)*loss_3\n",
    "        # loss = b*loss_1 + (1-b)*loss_2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss_fn_1(final_student, targets).item()\n",
    "        # train_loss += loss_1.item()\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset_sacertis(dir, False, False, True,  sensor = \"None\", time_frequency = \"frequency\")\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset, shuffle=False,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    pin_memory='store_true',\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = student\n",
    "\n",
    "y_predicted, y_test = evaluate_finetune(data_loader_test, model_to_evaluate, device)\n",
    "compute_accuracy(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_path = \"/home/benfenati/code/tle-supervised/Results/checkpoints/checkpoint-student-finetune-sacertis.pth\"\n",
    "torch.save(student, student_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
